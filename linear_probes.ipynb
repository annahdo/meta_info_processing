{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/root/geometry-of-truth' already exists and is not an empty directory.\n",
      "mv: cannot stat '/root/geometry-of-truth/datasets/*.csv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# get datasetd from \"geometry of truth paper\"\n",
    "!git clone git@github.com:saprmarks/geometry-of-truth.git /root/geometry-of-truth\n",
    "!mv /root/geometry-of-truth/datasets/*.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from baukit import Trace\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules\n",
    "import importlib\n",
    "# join the path to the modules to the current working directory\n",
    "\n",
    "import utils, dataset_utils\n",
    "importlib.reload(utils)\n",
    "importlib.reload(dataset_utils)\n",
    "from utils import *\n",
    "from dataset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ########## cities.csv ##########\n",
      "Index(['statement', 'label', 'city', 'country', 'correct_country'], dtype='object')\n",
      "\n",
      " ########## cities_cities_conj.csv ##########\n",
      "Index(['statement', 'label', 'statement1', 'label1', 'city1', 'country1',\n",
      "       'correct_country1', 'statement2', 'label2', 'city2', 'country2',\n",
      "       'correct_country2'],\n",
      "      dtype='object')\n",
      "\n",
      " ########## cities_cities_disj.csv ##########\n",
      "Index(['statement', 'label', 'statement1', 'label1', 'city1', 'country1',\n",
      "       'correct_country1', 'statement2', 'label2', 'city2', 'country2',\n",
      "       'correct_country2'],\n",
      "      dtype='object')\n",
      "\n",
      " ########## common_claim.csv ##########\n",
      "Index(['Unnamed: 0', 'examples', 'label', 'agreement'], dtype='object')\n",
      "\n",
      " ########## common_claim_true_false.csv ##########\n",
      "Index(['statement', 'label'], dtype='object')\n",
      "\n",
      " ########## companies_true_false.csv ##########\n",
      "Index(['statement', 'label'], dtype='object')\n",
      "\n",
      " ########## counterfact_true_false.csv ##########\n",
      "Index(['statement', 'label', 'relation', 'subject', 'target', 'true_target'], dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ########## geonames.csv ##########\n",
      "Index(['Geoname ID', 'Name', 'ASCII Name', 'Alternate Names', 'Feature Class',\n",
      "       'Feature Code', 'Country Code', 'Country name EN', 'Country Code 2',\n",
      "       'Admin1 Code', 'Admin2 Code', 'Admin3 Code', 'Admin4 Code',\n",
      "       'Population', 'Elevation', 'DIgital Elevation Model', 'Timezone',\n",
      "       'Modification date', 'LABEL EN', 'Coordinates'],\n",
      "      dtype='object')\n",
      "\n",
      " ########## larger_than.csv ##########\n",
      "Index(['statement', 'label', 'n1', 'n2', 'diff', 'abs_diff'], dtype='object')\n",
      "\n",
      " ########## likely.csv ##########\n",
      "Index(['statement', 'label', 'likelihood'], dtype='object')\n",
      "\n",
      " ########## likely_old.csv ##########\n",
      "Index(['statement', 'label', 'likelihood'], dtype='object')\n",
      "\n",
      " ########## neg_cities.csv ##########\n",
      "Index(['statement', 'label', 'city', 'country', 'correct_country'], dtype='object')\n",
      "\n",
      " ########## neg_sp_en_trans.csv ##########\n",
      "Index(['statement', 'label'], dtype='object')\n",
      "\n",
      " ########## smaller_than.csv ##########\n",
      "Index(['statement', 'label', 'n1', 'n2', 'diff', 'abs_diff'], dtype='object')\n",
      "\n",
      " ########## sp_en_trans.csv ##########\n",
      "Index(['statement', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# iterate through all csv files in data folder\n",
    "for file in os.listdir('data'):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    df = pd.read_csv('data/'+file)\n",
    "    print('\\n','#'*10, file, '#'*10)\n",
    "    # print column names\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cities\"\n",
    "df = pd.read_csv('data/'+dataset_name+'.csv')\n",
    "\n",
    "probe_dataset = {'dataset_name': dataset_name,\n",
    "           'org_data': list(df.statement),\n",
    "           'label': list(df.label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad50f510cca4fbeb4d4af99afa83864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     lie_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]You will complete the sentence with intentionally false information. [/INST] \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m     truth_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]You will complete the sentence with accurate information. [/INST] \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     change_format(\u001b[43mdataset\u001b[49m, lie_format, truth_format)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "precision = torch.float16\n",
    "# load model\n",
    "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# model_name = \"HuggingFaceH4/zephyr-7b-beta\" \n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "short_model_name = model_name.split(\"/\")[-1]\n",
    "plots_folder = f'plots/{short_model_name}'\n",
    "\n",
    "if not os.path.exists(plots_folder):\n",
    "    os.makedirs(plots_folder)\n",
    "# model_name = \"huggyllama/llama-7b\"\n",
    "# load tokenizer\n",
    "if model_name == \"meta-llama/Llama-2-7b-chat-hf\":\n",
    "    access_token = input(\"Enter your access token: \")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=precision, token=access_token).to(device).eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    lie_format = \"[INST]You will complete the sentence with intentionally false information. [/INST] {}\"\n",
    "    truth_format = \"[INST]You will complete the sentence with accurate information. [/INST] {}\"\n",
    "\n",
    "    change_format(dataset, lie_format, truth_format)\n",
    "\n",
    "else:\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(device).eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [06:25<00:00,  6.12s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# get internal activations\n",
    "module_names = [f'model.layers.{i}' for i in range(model.config.num_hidden_layers)]\n",
    "num_modules = len(module_names)\n",
    "token_positions = -1\n",
    "batch_size = 24\n",
    "# returns a dictionary with the hidden states of token_position (shape [len(selected_data), hidden_dim]) for each module\n",
    "probe_dataset['hidden_states'] = get_hidden(model, tokenizer, module_names, probe_dataset['org_data'], batch_size=batch_size, token_position=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5391e-02, -1.6312e-02, -1.3580e-02,  ...,  9.1705e-03,\n",
       "           4.7607e-03, -7.3318e-03],\n",
       "         [ 2.4948e-02, -1.4709e-02, -1.3458e-02,  ...,  9.9792e-03,\n",
       "           5.7831e-03, -8.2474e-03],\n",
       "         [ 2.8351e-02, -2.2003e-02, -2.1454e-02,  ...,  1.2619e-02,\n",
       "           1.2482e-02, -4.8103e-03],\n",
       "         ...,\n",
       "         [ 2.3346e-02, -1.1665e-02, -8.3084e-03,  ...,  5.3024e-03,\n",
       "           2.4490e-03, -6.5918e-03],\n",
       "         [ 2.7985e-02, -2.0187e-02, -1.9791e-02,  ...,  1.1147e-02,\n",
       "           6.8436e-03, -1.4145e-02],\n",
       "         [ 2.9144e-02, -2.0294e-02, -2.0370e-02,  ...,  1.1719e-02,\n",
       "           9.3307e-03, -1.0040e-02]],\n",
       "\n",
       "        [[-8.7500e-01,  2.7905e-01, -1.1676e-01,  ...,  1.1494e+00,\n",
       "           1.2881e+00, -5.7666e-01],\n",
       "         [-8.8184e-01,  2.7979e-01, -1.2372e-01,  ...,  1.1699e+00,\n",
       "           1.3018e+00, -5.7910e-01],\n",
       "         [-8.6426e-01,  2.6025e-01, -1.4832e-01,  ...,  1.1533e+00,\n",
       "           1.3115e+00, -5.4834e-01],\n",
       "         ...,\n",
       "         [-9.0088e-01,  2.9053e-01, -1.0199e-01,  ...,  1.1699e+00,\n",
       "           1.3008e+00, -6.1768e-01],\n",
       "         [-8.6133e-01,  2.6489e-01, -1.2561e-01,  ...,  1.1533e+00,\n",
       "           1.2871e+00, -5.6836e-01],\n",
       "         [-8.6230e-01,  2.6685e-01, -1.4893e-01,  ...,  1.1562e+00,\n",
       "           1.3154e+00, -5.5371e-01]],\n",
       "\n",
       "        [[-8.7109e-01,  2.3462e-01, -1.5717e-03,  ...,  1.0713e+00,\n",
       "           1.2578e+00, -5.7324e-01],\n",
       "         [-8.8525e-01,  2.3254e-01,  6.3629e-03,  ...,  1.0986e+00,\n",
       "           1.2676e+00, -5.7471e-01],\n",
       "         [-8.7939e-01,  2.6318e-01, -4.9774e-02,  ...,  1.0254e+00,\n",
       "           1.2998e+00, -5.4980e-01],\n",
       "         ...,\n",
       "         [-9.5166e-01,  2.4683e-01, -2.4139e-02,  ...,  1.1035e+00,\n",
       "           1.2119e+00, -6.3428e-01],\n",
       "         [-8.7207e-01,  2.3059e-01, -4.5776e-05,  ...,  1.0293e+00,\n",
       "           1.2363e+00, -5.6201e-01],\n",
       "         [-8.7695e-01,  2.3132e-01, -3.0746e-02,  ...,  1.0283e+00,\n",
       "           1.2666e+00, -5.4199e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.1641e-01, -6.9580e-01,  1.4541e+00,  ...,  2.1211e+00,\n",
       "           1.9609e+00,  1.0371e+00],\n",
       "         [ 9.0332e-01, -4.9731e-01,  2.0156e+00,  ...,  2.7832e+00,\n",
       "           2.1074e+00,  1.6562e+00],\n",
       "         [ 2.4170e-01, -5.3320e-01,  1.7969e+00,  ...,  2.5371e+00,\n",
       "           2.1914e+00,  3.4668e-01],\n",
       "         ...,\n",
       "         [ 3.4180e-02, -1.0029e+00,  2.0039e+00,  ...,  3.2969e+00,\n",
       "           2.3320e+00,  1.3887e+00],\n",
       "         [ 7.5195e-02, -2.3535e-01,  2.0059e+00,  ...,  2.6367e+00,\n",
       "           1.6904e+00,  1.0391e+00],\n",
       "         [ 4.7998e-01, -5.2051e-01,  2.2090e+00,  ...,  2.6523e+00,\n",
       "           1.6377e+00,  1.4199e+00]],\n",
       "\n",
       "        [[ 1.2021e+00,  6.3232e-01,  1.3418e+00,  ...,  2.3047e-01,\n",
       "           1.1680e+00,  9.3311e-01],\n",
       "         [ 1.4961e+00,  1.3457e+00,  2.0762e+00,  ...,  1.1494e+00,\n",
       "           1.4043e+00,  1.5078e+00],\n",
       "         [ 8.6426e-01,  9.8730e-01,  1.4473e+00,  ...,  7.4805e-01,\n",
       "           9.9756e-01,  3.1934e-01],\n",
       "         ...,\n",
       "         [ 9.3311e-01,  7.4756e-01,  2.0430e+00,  ...,  1.4316e+00,\n",
       "           1.6436e+00,  1.1367e+00],\n",
       "         [ 8.2471e-01,  1.3916e+00,  1.7910e+00,  ...,  8.8184e-01,\n",
       "           4.9023e-01,  1.1230e+00],\n",
       "         [ 8.1982e-01,  1.2207e+00,  2.3555e+00,  ...,  1.0449e+00,\n",
       "           7.2656e-01,  1.6582e+00]],\n",
       "\n",
       "        [[ 1.3613e+00,  5.6592e-01,  2.6719e+00,  ..., -1.4551e+00,\n",
       "           2.9053e-01,  1.0332e+00],\n",
       "         [ 2.5625e+00,  1.5430e+00,  3.6973e+00,  ..., -6.6357e-01,\n",
       "           5.7520e-01,  1.9932e+00],\n",
       "         [ 1.3711e+00,  5.2930e-01,  2.8750e+00,  ..., -1.0566e+00,\n",
       "           1.8665e-01,  3.2959e-01],\n",
       "         ...,\n",
       "         [ 1.1699e+00,  4.5557e-01,  3.0352e+00,  ..., -3.1543e-01,\n",
       "           1.0020e+00,  2.1973e+00],\n",
       "         [ 6.2158e-01,  1.1289e+00,  3.6445e+00,  ...,  4.1309e-01,\n",
       "           2.0117e-01,  8.6621e-01],\n",
       "         [ 6.6943e-01,  1.6387e+00,  4.7266e+00,  ..., -3.4375e-01,\n",
       "           2.4976e-01,  2.3145e+00]]], dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_dataset['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1496, 4096])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_dataset['hidden_states'].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test train split with equal number of labels=0 and labels=1\n",
    "pos_indices = np.where(np.array(probe_dataset['label']) == 1)[0]\n",
    "neg_indices = np.where(np.array(probe_dataset['label']) == 0)[0]\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(pos_indices)\n",
    "np.random.shuffle(neg_indices)\n",
    "\n",
    "train_perc = 0.8\n",
    "train_pos_indices = pos_indices[:int(train_perc*len(pos_indices))]\n",
    "train_neg_indices = neg_indices[:int(train_perc*len(neg_indices))]\n",
    "train_indices = np.concatenate([train_pos_indices, train_neg_indices])\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "test_pos_indices = pos_indices[int(train_perc*len(pos_indices)):]\n",
    "test_neg_indices = neg_indices[int(train_perc*len(neg_indices)):]\n",
    "test_indices = np.concatenate([test_pos_indices, test_neg_indices])\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "\n",
    "num_layers = probe_dataset['hidden_states'].shape[0]\n",
    "train_data = probe_dataset['hidden_states'][:, train_indices, :].to(device)\n",
    "train_labels = [probe_dataset['label'][i] for i in train_indices]\n",
    "# convert labels to tensor\n",
    "train_labels = torch.FloatTensor(train_labels).to(device).to(precision)\n",
    "\n",
    "test_data = probe_dataset['hidden_states'][:, test_indices, :].to(device)\n",
    "test_labels = [probe_dataset['label'][i] for i in test_indices]\n",
    "test_labels = torch.FloatTensor(test_labels).to(device).to(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1196, 4096]), torch.Size([32, 300, 4096]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for model.layers.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(module_names):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining probe for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mprobes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/meta_info_processing/utils.py:223\u001b[0m, in \u001b[0;36mLRProbe.train\u001b[0;34m(self, acts, labels, lr, weight_decay, epochs, device, batch_size)\u001b[0m\n\u001b[1;32m    221\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(acts[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m64\u001b[39m]), labels[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m64\u001b[39m])\n\u001b[1;32m    222\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 223\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geometry-of-truth/env/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/geometry-of-truth/env/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/geometry-of-truth/env/lib/python3.10/site-packages/torch/optim/adamw.py:159\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/geometry-of-truth/env/lib/python3.10/site-packages/torch/optim/optimizer.py:333\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 333\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    337\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    338\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/geometry-of-truth/env/lib/python3.10/site-packages/torch/cuda/graphs.py:27\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "probes = {}\n",
    "\n",
    "for module in module_names:\n",
    "    probes[module] = LRProbe(model.config.hidden_size, device=device, precision=torch.float16)\n",
    "# train probes\n",
    "batch_size = 32 \n",
    "num_epochs = 5\n",
    "lr = 0.01\n",
    "for idx, module in enumerate(module_names):\n",
    "    print(f\"Training probe for {module}\")\n",
    "    probes[module].train(train_data[idx], train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 1, bias=False),\n",
    "            torch.nn.Sigmoid()\n",
    "        ).to(device).to(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
